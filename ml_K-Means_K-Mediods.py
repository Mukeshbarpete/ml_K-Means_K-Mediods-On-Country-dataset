# -*- coding: utf-8 -*-
"""ML_assign1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jlv71OWA6mpXD6YknxBVJnyo7QQReDAS

Import Modules
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import seaborn as sn

from google.colab import drive
drive.mount('/content/drive')

"""importing dataset from country-data.csv"""

# Importing the dataset
dataset = pd.read_csv('Country-data.csv')
print("Import Dataset:")
dataset

#data cleaning
dataset = dataset.dropna()
print("Dataset After droping NULL entries:")
dataset

"""Dataset after Removing first colum(Name of contries"""

dataset1 = dataset.iloc[:,1:]
print("Dataset after Removing first colum(Name of contries:)")
dataset1

"""Scaling of Dataset"""

# Scaling dataset.
dataset_scaled = dataset[["child_mort","exports","health","imports","income","inflation","life_expec","total_fer","gdpp"]]
scaler = StandardScaler()
dataset_scaled = scaler.fit_transform(dataset_scaled)
#dataset_scaled = pd.DataFrame(dataset_scaled)
dataset_scaled

"""Correlation matrix for given dataset"""

#Correlation Matrix
print("Correlation Matrix")
plt.figure(figsize = (12, 7))
sn.heatmap(dataset.corr(), annot = True, cmap="CMRmap_r")
plt.show()

pip install scikit-learn-extra

"""Plotting silhouette score for varying sizes using K-Means clustering"""

#Plotting silhouette score for varying sizes using K-Means clustering
from sklearn.metrics import silhouette_score
silhouettes_dict1 = {}
for num_clusters in range(2,15):
    kmeans = KMeans(n_clusters=num_clusters,random_state=10,max_iter=50 )
    kmeans.fit(dataset_scaled)
    score = silhouette_score(dataset_scaled, kmeans.labels_)
    silhouettes_dict1[num_clusters]=score
print("Silhouette Score for K-Means")
print(f'Silhouettes score per cluster: {silhouettes_dict1} \n ')
plt.figure(figsize=(12, 7))
#plt.subplot(1,2,2)
plt.plot(list(silhouettes_dict1.keys()),list(silhouettes_dict1.values()),color='blue')
plt.xlabel('Number of clusters')
plt.ylabel('Silhouette score')

"""3 clusters for given dataset using k-means clustering"""

kmeans = KMeans(n_clusters=3,random_state=10,max_iter=50 )
kmeans.fit(dataset_scaled)
cluster1=kmeans.labels_

"""pair plot for kmeans clustering"""

dataKMeans=pd.DataFrame(dataset_scaled)
dataKMeans['cluster1']=cluster1
sn.pairplot(dataKMeans , hue="cluster1")
print("Showing pair plot for Kmeans ")

"""Plotting silhouette score for varying sizes using K-KMedoids clustering"""

#Plotting silhouette score for varying sizes using K-KMedoids clustering
from sklearn_extra.cluster import KMedoids
from sklearn.metrics import silhouette_score
silhouettes_dict2 = {}
for num_clusters in range(2,15):
    kmedoids = KMedoids(n_clusters=num_clusters,random_state=20,max_iter=40 )
    kmedoids.fit(dataset_scaled)
    score = silhouette_score(dataset_scaled, kmedoids.labels_)
    silhouettes_dict2[num_clusters]=score
print("Silhouette Score for K-Means")
print(f'Silhouettes score per cluster: {silhouettes_dict2} \n ')
plt.figure(figsize=(12, 7))
#plt.subplot(1,2,2)
plt.plot(list(silhouettes_dict2.keys()),list(silhouettes_dict2.values()),color='blue')
plt.xlabel('Number of clusters')
plt.ylabel('Silhouette score')

"""3 clusters for given dataset using k-medoids clustering"""

kmedoids = KMedoids(n_clusters=3,random_state=20,max_iter=40 )
kmedoids.fit(dataset_scaled)
cluster2=kmedoids.labels_

"""pair plot for KMedoids clustering"""

#plotting for KMedoids
dataKMedoids=pd.DataFrame(dataset_scaled)
dataKMedoids['cluster2']=cluster2
sn.pairplot(dataKMedoids , hue="cluster2")
print("Showing pair plot for Kmedoids ")

#for kMeans cluster count
print("Number of countries in each clusters using kmeans")
model=KMeans(n_clusters=3,random_state=20)
model.fit(dataset_scaled)

pd.Series(model.labels_).value_counts()

#for Kmedoids cluster count
print("Number of countries in each clusters using KMedoids clustering :")
model=KMedoids(n_clusters=3,random_state=20)
model.fit(dataset_scaled)

pd.Series(model.labels_).value_counts()